{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 1 – Traffic Light Reflex Agent**\n",
        "Design a simple reflex agent for traffic control. <br>\n",
        "**Environment states:**\n",
        "- Heavy Traffic\n",
        "- Light Traffic <br>\n",
        "**Rules:** <br>\n",
        "If Heavy → Green for longer <br>\n",
        "If Light → Normal Green <br>\n",
        "**Sample Output:** <br>\n",
        "Percept: Heavy Traffic → Action: Extend Green Time <br>\n",
        "Percept: Light Traffic → Action: Normal Green"
      ],
      "metadata": {
        "id": "5N2qMNpI0ZhC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNBEcjuK0WsV",
        "outputId": "a4d68504-a7fe-4f96-a1a3-041faee94cc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percept: Heavy -> Action: Extend Green Time\n",
            "Percept: Light -> Action: Normal Green\n"
          ]
        }
      ],
      "source": [
        "class Environment:\n",
        "  def __init__(self, traffic):\n",
        "    self.traffic = traffic\n",
        "\n",
        "  def get_percept(self):\n",
        "    return self.traffic\n",
        "\n",
        "class SimpleReflexAgent:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def act(self, percept):\n",
        "    if percept == \"Heavy\":\n",
        "      return \"Extend Green Time\"\n",
        "    else:\n",
        "      return \"Normal Green\"\n",
        "\n",
        "def agent_program(agent, environment):\n",
        "  percept = environment.get_percept()\n",
        "  action = agent.act(percept)\n",
        "  print(f\"Percept: {percept} -> Action: {action}\")\n",
        "\n",
        "agent1 = SimpleReflexAgent()\n",
        "environment1 = Environment(\"Heavy\")\n",
        "agent_program(agent1, environment1)\n",
        "\n",
        "agent2 = SimpleReflexAgent()\n",
        "environment2 = Environment(\"Light\")\n",
        "agent_program(agent2, environment2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 2 – Smart Classroom Light Controller (Model-Based Agent)**\n",
        "Design a Model-Based Agent that controls classroom lights. <br>\n",
        "**Environment States:** <br>\n",
        "• Students Present: Yes / No <br>\n",
        "• Light Status: ON / OFF <br>\n",
        "**Agent Model (Memory):** <br>\n",
        "The agent must store: <br>\n",
        "• Previous student presence <br>\n",
        "• Previous light status <br>\n",
        "**Rules:**\n",
        "1. If students are present and lights are OFF → Turn lights ON\n",
        "2. If no students and lights are ON → Turn lights OFF\n",
        "3. Otherwise → No action <br>\n",
        "The agent must update and display its internal model after each step.\n",
        "Student presence should be randomly generated every iteration.\n",
        "Run for 8 steps."
      ],
      "metadata": {
        "id": "U57HztGq_HtC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Environment:\n",
        "  def __init__(self, students_present, light_status):\n",
        "    self.students_present = students_present\n",
        "    self.light_status = light_status\n",
        "\n",
        "  def get_percept(self):\n",
        "    return {\"Students_Present\": self.students_present, \"Light_Status\": self.light_status};\n",
        "\n",
        "  def turn_on_light(self):\n",
        "    self.light_status = \"ON\"\n",
        "\n",
        "  def turn_off_light(self):\n",
        "    self.light_status = \"OFF\"\n",
        "\n",
        "  def randomize_students_present(self):\n",
        "    import random\n",
        "    self.students_present = random.choice([\"Yes\", \"No\"])\n",
        "\n",
        "class ModelBasedAgent:\n",
        "  def __init__(self):\n",
        "    self.internal_model = {\"Students_Present\": None, \"Light_Status\": None }\n",
        "\n",
        "  def update_model(self, percept):\n",
        "    self.internal_model.update(percept)\n",
        "\n",
        "  def act(self, percept):\n",
        "    self.update_model(percept)\n",
        "    print(\"Internal Model (Previous States): \", self.internal_model)\n",
        "\n",
        "    if (self.internal_model[\"Students_Present\"] == \"Yes\" and self.internal_model[\"Light_Status\"] == \"OFF\"):\n",
        "      return \"Turn lights ON\"\n",
        "    elif (self.internal_model[\"Students_Present\"] == \"No\" and self.internal_model[\"Light_Status\"] == \"ON\"):\n",
        "      return \"Turn lights OFF\"\n",
        "    else:\n",
        "      return \"No action\"\n",
        "\n",
        "def agent_program(agent, environment):\n",
        "  for i in range(8):\n",
        "    environment.randomize_students_present()\n",
        "    percept = environment.get_percept()\n",
        "    action = agent.act(percept)\n",
        "    print(f\"Percept: {percept} -> Action: {action}\\n\")\n",
        "    if action == \"Turn lights ON\":\n",
        "      environment.turn_on_light()\n",
        "    elif action == \"Turn lights OFF\":\n",
        "      environment.turn_off_light()\n",
        "\n",
        "agent1 = ModelBasedAgent()\n",
        "environment1 = Environment(\"No\", \"ON\")\n",
        "agent_program(agent1, environment1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhiR5Qfi_jPL",
        "outputId": "495388f4-8121-4c88-8a69-5d5038825d0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Internal Model (Previous States):  {'Students_Present': 'No', 'Light_Status': 'ON'}\n",
            "Percept: {'Students_Present': 'No', 'Light_Status': 'ON'} -> Action: Turn lights OFF\n",
            "\n",
            "Internal Model (Previous States):  {'Students_Present': 'Yes', 'Light_Status': 'OFF'}\n",
            "Percept: {'Students_Present': 'Yes', 'Light_Status': 'OFF'} -> Action: Turn lights ON\n",
            "\n",
            "Internal Model (Previous States):  {'Students_Present': 'No', 'Light_Status': 'ON'}\n",
            "Percept: {'Students_Present': 'No', 'Light_Status': 'ON'} -> Action: Turn lights OFF\n",
            "\n",
            "Internal Model (Previous States):  {'Students_Present': 'No', 'Light_Status': 'OFF'}\n",
            "Percept: {'Students_Present': 'No', 'Light_Status': 'OFF'} -> Action: No action\n",
            "\n",
            "Internal Model (Previous States):  {'Students_Present': 'No', 'Light_Status': 'OFF'}\n",
            "Percept: {'Students_Present': 'No', 'Light_Status': 'OFF'} -> Action: No action\n",
            "\n",
            "Internal Model (Previous States):  {'Students_Present': 'No', 'Light_Status': 'OFF'}\n",
            "Percept: {'Students_Present': 'No', 'Light_Status': 'OFF'} -> Action: No action\n",
            "\n",
            "Internal Model (Previous States):  {'Students_Present': 'Yes', 'Light_Status': 'OFF'}\n",
            "Percept: {'Students_Present': 'Yes', 'Light_Status': 'OFF'} -> Action: Turn lights ON\n",
            "\n",
            "Internal Model (Previous States):  {'Students_Present': 'Yes', 'Light_Status': 'ON'}\n",
            "Percept: {'Students_Present': 'Yes', 'Light_Status': 'ON'} -> Action: No action\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 3 – Student Study Planner (Goal-Based Agent)**\n",
        "**Goal:** Complete all subjects. <br>\n",
        "**Subjects **bold text**:**\n",
        "AI, Math, Physics<br>\n",
        "Agent studies unfinished subjects until all completed. <br>\n",
        "**Sample Output:** <br>\n",
        "Studying AI <br>\n",
        "Studying Math <br>\n",
        "Studying Physics <br>\n",
        "**Goal Achieved:** All subjects completed"
      ],
      "metadata": {
        "id": "xcR6hBimFVf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Environment:\n",
        "  def __init__(self):\n",
        "    self.subjects = {\"AI\": \"unfinished\", \"Math\": \"unfinished\", \"Physics\": \"unfinished\"}\n",
        "\n",
        "  def get_percept(self, position):\n",
        "    return self.subjects[position]\n",
        "\n",
        "  def mark_completed(self, position):\n",
        "    self.subjects[position] = \"completed\"\n",
        "\n",
        "class GoalBasedAgent:\n",
        "  def __init__(self):\n",
        "    self.goal = \"completed\"\n",
        "\n",
        "  def formulate_goal(self, percept):\n",
        "    if percept == \"unfinished\":\n",
        "      self.goal = \"Study Subject\"\n",
        "    else:\n",
        "      self.goal = \"Do Nothing\"\n",
        "\n",
        "  def act(self, percept):\n",
        "    self.formulate_goal(percept)\n",
        "    if self.goal == \"Study Subject\":\n",
        "      return \"Study Subject\"\n",
        "    else:\n",
        "      return \"Subject Completed\"\n",
        "\n",
        "def agent_program(agent, environment):\n",
        "  print(\"Initial State: \", environment.subjects)\n",
        "\n",
        "  for position in environment.subjects:\n",
        "    percept = environment.get_percept(position)\n",
        "    action = agent.act(percept)\n",
        "\n",
        "    if action == \"Study Subject\":\n",
        "          print(f\"Studying {position}\")\n",
        "          environment.mark_completed(position)\n",
        "  print(\"Goal Achieved: All subjects completed\")\n",
        "\n",
        "agent1 = GoalBasedAgent()\n",
        "environment1 = Environment()\n",
        "agent_program(agent1, environment1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84dD0w2uFzNQ",
        "outputId": "7eb68cd5-4f1b-4cfc-e297-ed53824267b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial State:  {'AI': 'unfinished', 'Math': 'unfinished', 'Physics': 'unfinished'}\n",
            "Studying AI\n",
            "Studying Math\n",
            "Studying Physics\n",
            "Goal Achieved: All subjects completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Task 4 – Restaurant Selector (Utility-Based Agent)**\n",
        "**Restaurants:** <br>\n",
        "A: Distance 3, Rating 7 <br>\n",
        "B: Distance 5, Rating 9 <br>\n",
        "**Utility =** Rating – Distance <br>\n",
        "**Output:** <br>\n",
        "Restaurant A Utility = 4 <br>\n",
        "Restaurant B Utility = 4 <br>\n",
        "Selected Restaurant: A"
      ],
      "metadata": {
        "id": "2-aL4wYXdQHB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Environment:\n",
        "  def __init__(self):\n",
        "    self.distances = {\"A\": 3, \"B\": 5}\n",
        "    self.ratings = {\"A\": 7, \"B\": 9}\n",
        "\n",
        "  def get_percept(self, restaurant):\n",
        "    return {\"Restaurant\": restaurant, \"Distance\": self.distances[restaurant], \"Rating\": self.ratings[restaurant]}\n",
        "\n",
        "class UtilityBasedAgent:\n",
        "  def __init__(self):\n",
        "    self.utility = None\n",
        "    self.bestRestaurant = None\n",
        "    self.bestUtility = 0\n",
        "\n",
        "  def calculate_utility(self, percept):\n",
        "    self.utility = percept[\"Rating\"] - percept[\"Distance\"]\n",
        "\n",
        "  def act(self, percept):\n",
        "    self.calculate_utility(percept)\n",
        "    print(f\"Restaurant {percept[\"Restaurant\"]} Utility = {self.utility}\")\n",
        "    if self.utility > self.bestUtility:\n",
        "      self.bestRestaurant = percept[\"Restaurant\"]\n",
        "      self.bestUtility = self.utility\n",
        "    return self.bestRestaurant\n",
        "\n",
        "def agent_program(agent, environment):\n",
        "  bestRestaurant = None\n",
        "  for restaurant in environment.distances:\n",
        "    percept = environment.get_percept(restaurant)\n",
        "    action = agent.act(percept)\n",
        "    if action == restaurant:\n",
        "      bestRestaurant = restaurant\n",
        "  print(f\"Selected Restaurant: {bestRestaurant}\")\n",
        "\n",
        "agent1 = UtilityBasedAgent()\n",
        "environment1 = Environment()\n",
        "agent_program(agent1, environment1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzVL6yHa5WTy",
        "outputId": "a7633557-efeb-4aed-862c-dcc2e486d8fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Restaurant A Utility = 4\n",
            "Restaurant B Utility = 4\n",
            "Selected Restaurant: A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 5 – Learning Agent Game**\n",
        "Learning agent chooses between: Play or Rest <br>\n",
        "**Rewards:** <br>\n",
        "Play → +5 <br>\n",
        "Rest → +1 <br>\n",
        "The agent runs for 10 iterations and updates its Q-values. <br>\n",
        "**Sample Output: **<br>\n",
        "Step 1: Action Play Reward 5 <br>\n",
        "Step 5: Action Play Reward 5 <br>\n",
        "Q-table Updated"
      ],
      "metadata": {
        "id": "dIFWzAtgZFSx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "class Environment:\n",
        "    def __init__(self):\n",
        "        self.state = \"Game\"\n",
        "\n",
        "    def get_percept(self):\n",
        "        return self.state\n",
        "\n",
        "    def get_reward(self, action):\n",
        "        if action == \"Play\":\n",
        "            return 5\n",
        "        else:\n",
        "            return 1\n",
        "\n",
        "class LearningBasedAgent:\n",
        "    def __init__(self, actions):\n",
        "        self.Q = {}\n",
        "        self.actions = actions\n",
        "        self.alpha = 0.1      # Learning rate\n",
        "        self.gamma = 0.9      # Discount factor\n",
        "        self.epsilon = 0.1    # Exploration rate\n",
        "\n",
        "    def get_Q_value(self, state, action):\n",
        "        return self.Q.get((state, action), 0.0)\n",
        "\n",
        "    def select_action(self, state):\n",
        "        if random.uniform(0, 1) < self.epsilon:\n",
        "            return random.choice(self.actions)\n",
        "        else:\n",
        "            return max(self.actions, key=lambda a: self.get_Q_value(state, a))\n",
        "\n",
        "    def learn(self, state, action, reward, next_state):\n",
        "        old_Q = self.get_Q_value(state, action)\n",
        "        best_future_Q = max([self.get_Q_value(next_state, a) for a in self.actions])\n",
        "        self.Q[(state, action)] = old_Q + self.alpha * (reward + self.gamma * best_future_Q - old_Q)\n",
        "\n",
        "    def act(self, state):\n",
        "        action = self.select_action(state)\n",
        "        return action\n",
        "\n",
        "def agent_program(agent, environment, steps):\n",
        "    for step in range(1, steps + 1):\n",
        "        percept = environment.get_percept()\n",
        "        action = agent.act(percept)\n",
        "        reward = environment.get_reward(action)\n",
        "        print(f\"Step {step}: Action {action} Reward {reward}\")\n",
        "        next_state = environment.get_percept()\n",
        "        agent.learn(percept, action, reward, next_state)\n",
        "    print(\"\\nQ-table Updated:\", agent.Q)\n",
        "\n",
        "agent = LearningBasedAgent([\"Play\", \"Rest\"])\n",
        "environment = Environment()\n",
        "agent_program(agent, environment, 10)"
      ],
      "metadata": {
        "id": "26LV9xiRdF2K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c57cb85-54b9-49f2-a97c-cdc2d713bc3e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: Action Play Reward 5\n",
            "Step 2: Action Play Reward 5\n",
            "Step 3: Action Play Reward 5\n",
            "Step 4: Action Play Reward 5\n",
            "Step 5: Action Play Reward 5\n",
            "Step 6: Action Rest Reward 1\n",
            "Step 7: Action Play Reward 5\n",
            "Step 8: Action Play Reward 5\n",
            "Step 9: Action Play Reward 5\n",
            "Step 10: Action Play Reward 5\n",
            "\n",
            "Q-table Updated: {('Game', 'Play'): 4.324137625817955, ('Game', 'Rest'): 0.3205447754500001}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 6 - Firefighting Robot**\n",
        "In a building with multiple rooms, a firefighting robot has been deployed to save lives and prevent damage. The building is represented by a 3x3 grid, where each cell corresponds to a room. Some rooms contain fires, and others are safe. <br>\n",
        "● The robot starts at room 'a' and must move across all rooms, from 'a' to 'j', detecting and extinguishing any fires along the way. <br>\n",
        "● The robot needs to be aware of which rooms have fire and must extinguish them by changing the room’s status from \"fire\" to \"safe.\" <br>\n",
        "● The robot needs to continuously display the environment’s status after each move and indicate when fires are detected and extinguished. <br>\n",
        "● **Initialization:** <br>\n",
        "○ Implement a 3x3 grid where rooms 'a', 'b', 'd', 'f', 'g', 'h' are safe (no fire), and rooms 'c', 'e', 'j' contain fires. <br>\n",
        "○ The robot starts at room 'a' and follows a predefined path: ['a', 'b', 'c', 'd','e', 'f', 'g', 'h', 'j']. <br>\n",
        "● **Robot Movement:** <br>\n",
        "○ The robot should move from room to room in the specified path. <br>\n",
        "○ At each room, the robot must check if there is a fire: <br>\n",
        "■ If there is a fire, extinguish it and update the room's status to safe. <br>\n",
        "■ If there is no fire, move to the next room. <br>\n",
        "\n",
        "● **Displaying the Environment:** <br>\n",
        "○ After each move, display the current status of the environment. <br>\n",
        "○ Use symbols like \" \" for fire and \" \" (space) for a safe room to represent the environment visually. <br>\n",
        "\n",
        "● **Final Output:** <br>\n",
        "○ After the robot has completed its movement, display the final status of all rooms (with all fires extinguished)."
      ],
      "metadata": {
        "id": "xWEkSMHbGMBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Environment:\n",
        "  def __init__(self):\n",
        "    self.rooms = {\"a\": \"safe\", \"b\": \"fire\", \"c\": \"fire\", \"d\": \"safe\", \"e\": \"fire\", \"f\": \"safe\", \"g\": \"safe\", \"h\": \"safe\", \"j\": \"fire\"}\n",
        "\n",
        "  def get_percept(self, position):\n",
        "    return self.rooms[position]\n",
        "\n",
        "  def mark_extinguished(self, position):\n",
        "    self.rooms[position] = \"safe\"\n",
        "\n",
        "  def display_rooms(self):\n",
        "    print(f\"Rooms: {self.rooms}\")\n",
        "\n",
        "class SimpleReflexAgent:\n",
        "  def act(self, percept):\n",
        "    if percept == \"fire\":\n",
        "      return \"Extinguish Fire\"\n",
        "    else:\n",
        "      return \"Move to Next Room\"\n",
        "\n",
        "def agent_program(agent, environment):\n",
        "  print(\"Initial State: \", environment.rooms, \"\\n\")\n",
        "  path = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"j\"]\n",
        "  for position in path:\n",
        "    percept = environment.get_percept(position)\n",
        "    action = agent.act(percept)\n",
        "    if action == \"Extinguish Fire\":\n",
        "      print(f\"Extinguishing Fire in {position}\")\n",
        "      environment.mark_extinguished(position)\n",
        "      environment.display_rooms()\n",
        "      print(\"\\n\")\n",
        "    else:\n",
        "      print(f\"safe in room {position}! moving to next room\")\n",
        "      environment.display_rooms()\n",
        "      print(\"\\n\")\n",
        "  print(\"Final State: \", environment.rooms)\n",
        "\n",
        "agent1 = SimpleReflexAgent()\n",
        "environment1 = Environment()\n",
        "agent_program(agent1, environment1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zt7JJ6MgHiUR",
        "outputId": "8faca90c-8b52-4a51-9c93-7a3ad03a7dd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial State:  {'a': 'safe', 'b': 'fire', 'c': 'fire', 'd': 'safe', 'e': 'fire', 'f': 'safe', 'g': 'safe', 'h': 'safe', 'j': 'fire'} \n",
            "\n",
            "safe in room a! moving to next room\n",
            "Rooms: {'a': 'safe', 'b': 'fire', 'c': 'fire', 'd': 'safe', 'e': 'fire', 'f': 'safe', 'g': 'safe', 'h': 'safe', 'j': 'fire'}\n",
            "\n",
            "\n",
            "Extinguishing Fire in b\n",
            "Rooms: {'a': 'safe', 'b': 'safe', 'c': 'fire', 'd': 'safe', 'e': 'fire', 'f': 'safe', 'g': 'safe', 'h': 'safe', 'j': 'fire'}\n",
            "\n",
            "\n",
            "Extinguishing Fire in c\n",
            "Rooms: {'a': 'safe', 'b': 'safe', 'c': 'safe', 'd': 'safe', 'e': 'fire', 'f': 'safe', 'g': 'safe', 'h': 'safe', 'j': 'fire'}\n",
            "\n",
            "\n",
            "safe in room d! moving to next room\n",
            "Rooms: {'a': 'safe', 'b': 'safe', 'c': 'safe', 'd': 'safe', 'e': 'fire', 'f': 'safe', 'g': 'safe', 'h': 'safe', 'j': 'fire'}\n",
            "\n",
            "\n",
            "Extinguishing Fire in e\n",
            "Rooms: {'a': 'safe', 'b': 'safe', 'c': 'safe', 'd': 'safe', 'e': 'safe', 'f': 'safe', 'g': 'safe', 'h': 'safe', 'j': 'fire'}\n",
            "\n",
            "\n",
            "safe in room f! moving to next room\n",
            "Rooms: {'a': 'safe', 'b': 'safe', 'c': 'safe', 'd': 'safe', 'e': 'safe', 'f': 'safe', 'g': 'safe', 'h': 'safe', 'j': 'fire'}\n",
            "\n",
            "\n",
            "safe in room g! moving to next room\n",
            "Rooms: {'a': 'safe', 'b': 'safe', 'c': 'safe', 'd': 'safe', 'e': 'safe', 'f': 'safe', 'g': 'safe', 'h': 'safe', 'j': 'fire'}\n",
            "\n",
            "\n",
            "safe in room h! moving to next room\n",
            "Rooms: {'a': 'safe', 'b': 'safe', 'c': 'safe', 'd': 'safe', 'e': 'safe', 'f': 'safe', 'g': 'safe', 'h': 'safe', 'j': 'fire'}\n",
            "\n",
            "\n",
            "Extinguishing Fire in j\n",
            "Rooms: {'a': 'safe', 'b': 'safe', 'c': 'safe', 'd': 'safe', 'e': 'safe', 'f': 'safe', 'g': 'safe', 'h': 'safe', 'j': 'safe'}\n",
            "\n",
            "\n",
            "Final State:  {'a': 'safe', 'b': 'safe', 'c': 'safe', 'd': 'safe', 'e': 'safe', 'f': 'safe', 'g': 'safe', 'h': 'safe', 'j': 'safe'}\n"
          ]
        }
      ]
    }
  ]
}